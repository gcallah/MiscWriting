# AI and Semiotics

Gene Callahan


## Introduction



Just What Is "AI"
Superintelligence?
Overlords?
Or just impressive software?







### AI Has Always Moved the Goalposts

Playing chess was thought to be cutting edge AI... until LLMs came along.




## The Nature of Mechanical Computation


What is a computer, really?

We're going to demystify computation.


### The Universal Turing Machine


In the late 1930s, Alan Turing described a remarkably simple theoretical machine—a tape, a read-write head, and a set of
rules—that could read, write, and move along the tape. Despite its simplicity, this model showed how any mechanical
computation could be performed.

(Turing, 1937)



#### The Church–Turing Thesis


Lambda calculus

(Church, 1936a, and Church 1936b)


No hardware upgrade expands what can be computed. Only how fast.





### How Does a Digital Computer "Compute"?

Modern computers are possible because any system with two reliable states—like on/off or hot/cold—can perform computation. 
[Peirce]


We use electronics not because they're theoretically superior, but because they're far faster, even though a water or
pneumatic computer could compute the same things.





### Building a Water Computer

Water
Pipes
Electrical Wires
Hot Water
High Voltage
Cold Water
Low Voltage

Electronics

Logically Identical



### Gates

At certain points, two of our water computer's pipes meet in engineered devices called gates, which will output either
hot or cold water based upon what arrives at the gate. 



We're going to interpret hot water coming out of the gate as meaning TRUE. And we're going to say that we only want our
gate to output TRUE if both pipes leading into the gate were feeding in TRUE, in other words, hot water.


Hot


Cold + Cold
Hot + Cold
Cold + Hot
Hot + Hot


AND Gate

### Interpreting the Output


But there is nothing intrinsic to the physical set up that determines it to be an AND gate: that is our interpretation.
With the exact same physical set up, but where we choose to interpret cold water as TRUE, the device becomes the opposite gate: a NAND gate.
So, even with the simplest of logical operations that occurs inside a computer, what the result means depends upon how we want to interpret it.



We don't even have to interpret the physical set up as a logic gate.
We might instead consider it... our water park's coin flipper.
Hot is heads and cold is tails!
If we designed the right "program" at the top of the hill, we can simulate random coin flips that produce half heads and half tails.
The "program" could be a set of instructions to people with pails of hot and cold water at the top of the hill.



If we buy a bigger hill, we can set up a working, water-based computer.
It will be very slow!

Let's say we have as few as 32 open pipes at the top of the hill where we can provide our computer with input. That gives us 4 billion possible combinations of "code" and "data."

Thirty-two people at the top of the hill input a program and some data it should process by pouring a combination of hot
and cold water into the open pipes at the top of the hill.
We are at the bottom of the hill, and see that a pattern of TRUE and FALSE, or ones and zeros, or hot and cold water, is our computer's output.
What is the meaning of this output in front of us?


Unless we know the meaning (if any) that the people at the top of the hill assigned to their inputs, we cannot know what the meaning of the output is.
We just see a bunch of hot and cold water coming out of pipes.
The inputs at the top could've been intended by the people with buckets to calculate a batting average, or generate a snippet of music, or pick out a good chess move.
Whether the program is "correct" is also entirely based upon what the inputs meant to the people doing the inputting. 



The Critical Question:
What does the output mean?


Meaning assigned by humans
Inputs → interpretation → outputs
Without shared meaning: nothing



In Peircean terms, a computing machine has no thirdness.


But Don't LLMs Change All This?


Modern LLMs may seem fundamentally different from a water computer, but similar claims were made for earlier
technologies, and all overlook the Church–Turing Thesis!


In principle, any system capable of computation can perform the same calculations, 

LLM training itself begins by
stripping inputs of meaning into abstract representations.



While impressive, modern machine learning has no metaphysical implications: it searches program space for models that are "good enough" at a task. 

The key breakthrough is attention, 

So-called "hallucinations" are simply statistical results.



What LLMs Actually Do


I asked ChatGPT: "Can you generate an image for me of the head from the CS Lewis novel That Hideous Strength?"

The only connections apparently were between "head" and "hideous":



## Applying semiotics to our computer


### C.S. Peirce


Chemist, surveyor, mathematician, logician, astronomer and founder of modern semiotics and pragmatism.

Bertrand Russell: "certainly the greatest American thinker ever."

"As early as 1886, he saw that logical operations could be carried out by electrical switching circuits."






Peirce developed the concept of secondness.

When a rock tumbling down a hill meets another falling rock and deflects its course, we have a purely dyadic relationship: neither rock means anything further when hitting its companion.



Secondness







Peirce pointed out that human language, on the other hand, is intrinsically a triadic relationship.

If I shout to you "A mind-reductionist is creeping up behind you!" I am not merely sending some sound waves to your eardrums: I am also referring to a third thing: the reductionist.
Sign
"Dog"
Object
Interpretant



Thirdness





Think about our water computer: the water flowing down the hill, means nothing by itself. It is only a shared meaning between the inputters at the top of the hill and the readers at the bottom of the hill that gives the program being run what meaning it possesses.

The bits that represent your department's accounts for the year could just as well be bits that represent a musical composition or an image to display: inside the computer they only exhibit secondness: e.g., high and low voltages hitting a gate making it emit a low volatage.




Thirdness and AI






John Searle
Objection: The system "as a whole" understands Chinese.
Yes, it does: so long as the "whole" is big enough to include the humans who set up the room!




Philosophical Reinforcement


Hilary Putnam showed essentially the complementary result: multiple physical states can have the same meaning: the
brains of a human, an octopus, and a Martian can all "represent" the experience of pain.

People speaking different languages can mean the same thing, even though their brains must be in different states (to produce different sounds, at least).

Thus, "meaning" cannot be reduced to a physical state.



Multiple Realizability




Computer programs are legisigns.



Types of Signs





We don't know how humans do
Nothing so far suggests more than secondness
The head in C.S. Lewis: possessed by a demon!



## Conclusion


Could AIs Become Conscious?






If an AI becomes intelligent, it will no longer be artificial — and no longer just a machine.


## Bibliography

- Church, A. (1936a). "A Note on the Entscheidungsproblem." Journal of Symbolic Logic, 1(1), 40–41, 101–102.

- Church, A. (1936b). "An Unsolvable Problem in Elementary Number Theory." American Journal of Mathematics, 58, 345–363.

- Turing, A. M. (1937). "On Computable Numbers, with an Application to the Entscheidungsproblem". Proceedings of the
London Mathematical Society. Series 2, Volume 42, Issue 1, pp. 230–265. 


